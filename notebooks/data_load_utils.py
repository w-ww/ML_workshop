# -*- coding: utf-8 -*-
"""
Created on Mon May 07 11:22:07 2018

"""

try:
    import configparser
except ImportError:
    import ConfigParser as configparser
import csv
import logging

class Settings:
    settings = None
    user = None
    @staticmethod
    def load_config(config_file):
            Settings.settings = configparser.ConfigParser()
            Settings.settings.read(config_file)
            try:
                url = Settings.settings.get("hana", "url")
            except:
                url = "unknown"
            try:
                port = Settings.settings.getint("hana", "port")
            except:
                port = 39015
            try:
                pwd = Settings.settings.get("hana", "passwd")
            except:
                pwd='pydevtest'
            try:
                Settings.user = Settings.settings.get("hana", "user")
            except:
                Settings.user = "PYDEVTEST"
            Settings._init_logger()
            return url, port, Settings.user, pwd

    @staticmethod
    def _set_log_level(logger, level):
        if level == 'info':
            logger.setLevel(logging.INFO)
        else:
            if level == 'warn':
                logger.setLevel(logging.WARN)
            else:
                if level == 'debug':
                    logger.setLevel(logging.DEBUG)
                else:
                    logger.setLevel(logging.ERROR)

    @staticmethod
    def _init_logger():
        logging.basicConfig()
        for c in ["hana_ml.ml_base", 'hana_ml.dataframe', 'hana_ml.algorithms.trees',
                  'hana_ml.algorithms.classification']:
            try:
                level = Settings.settings.get("logging", c)
            except:
                level = "error"
            logger = logging.getLogger(c)
            Settings._set_log_level(logger, level.lower())  #logger.setLevel(logging.INFO)
        #logger.addHandler(logging.NullHandler())

class DataSets:

    @staticmethod
    def _load_data(connection, table_descriptions, cols, inlist):
        for k,v in table_descriptions.items():
            sql = "DROP TABLE " + v[0]
            try:
                with connection.connection.cursor() as cur:
                    #print(sql)
                    cur.execute(sql)
            except:
                print("Drop unsuccessful")
                pass
    
            sql = 'CREATE COLUMN TABLE ' + v[0] + cols
            with connection.connection.cursor() as cur:
                #print(sql)
                cur.execute(sql)
    
            with open(v[1], 'r') as my_file:
                reader = csv.reader(my_file, delimiter=',')
                data = list(reader)
                sql = 'insert into ' + v[0] + inlist
                with connection.connection.cursor() as cur:
                    rows_inserted = cur.executemany(sql, data)
                    #print ("Rows inserted into %s: %s" % (v[0], len(rows_inserted)))

    @staticmethod
    def load_bank_data(connection, schema=None):
        if schema is None:
            schema = Settings.user
        full_tbl = "DBM2_RFULL_TBL"
        training_tbl = "DBM2_RTRAINING_TBL"
        validation_tbl = "DBM2_RVALIDATION_TBL"
        test_tbl = "DBM2_RTEST_TBL"
        full_tbl_fq = schema + '.' + full_tbl
        training_tbl_fq = schema + '.' + training_tbl
        validation_tbl_fq = schema + '.' + validation_tbl
        test_tbl_fq = schema + '.' + test_tbl
        table_descriptions = {
                              'full':       [full_tbl_fq, '../datasets/bank-additional-full.csv'],
                              'train':      [training_tbl_fq, '../datasets/bank-additional-train.csv'],
                              'validation': [validation_tbl_fq, '../datasets/bank-additional-validation.csv'],
                              'test':       [test_tbl_fq, '../datasets/bank-additional-test.csv']
                             }
    
        cols = '( \
                ID INTEGER generated by default as identity,\
                AGE INTEGER,\
                JOB VARCHAR(256),\
                MARITAL VARCHAR(100),\
                EDUCATION VARCHAR(256),\
                DBM_DEFAULT VARCHAR(100),\
                HOUSING VARCHAR(100),\
                LOAN VARCHAR(100),\
                CONTACT VARCHAR(100),\
                DBM_MONTH VARCHAR(100),\
                DAY_OF_WEEK VARCHAR(100),\
                DURATION DOUBLE,\
                CAMPAIGN INTEGER,\
                PDAYS INTEGER,\
                PREVIOUS INTEGER,\
                POUTCOME VARCHAR(100),\
                EMP_VAR_RATE DOUBLE,\
                CONS_PRICE_IDX DOUBLE,\
                CONS_CONF_IDX DOUBLE,\
                EURIBOR3M DOUBLE,\
                NREMPLOYED INTEGER,\
                LABEL VARCHAR(10)\
                )'
        inlist = '("ID", "AGE", "JOB", "MARITAL", "EDUCATION",\
                    "DBM_DEFAULT", "HOUSING", "LOAN", "CONTACT", "DBM_MONTH", "DAY_OF_WEEK", \
                    "DURATION", "CAMPAIGN", "PDAYS", "PREVIOUS", "POUTCOME", \
                    "EMP_VAR_RATE", "CONS_PRICE_IDX", "CONS_CONF_IDX", "EURIBOR3M", \
                    "NREMPLOYED", "LABEL") \
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'

        DataSets._load_data(connection, table_descriptions, cols, inlist)
        return full_tbl, training_tbl, validation_tbl, test_tbl

    @staticmethod
    def load_iris_data(connection, schema=None):
        if schema is None:
            schema = Settings.user
        full_tbl = "IRIS_DATA_FULL_TBL"
        training_tbl = "IRIS_DATA_TRAIN_TBL"
        validation_tbl = "IRIS_DATA_VALIDATION_TBL"
        test_tbl = "IRIS_DATA_TEST_TBL"
        full_tbl_fq = schema + '.' + full_tbl
        training_tbl_fq = schema + '.' + training_tbl
        validation_tbl_fq = schema + '.' + validation_tbl
        test_tbl_fq = schema + '.' + test_tbl
        table_descriptions = {
                      'full':       [full_tbl_fq, '../datasets/iris.csv'],
                      'train':      [training_tbl_fq, '../datasets/iris-train.csv'],
                      'validation': [validation_tbl_fq, '../datasets/iris-validation.csv'],
                      'test':       [test_tbl_fq, '../datasets/iris-test.csv']
                      }
        cols = '( \
        ID INTEGER generated by default as identity,\
        SEPALLENGTHCM DOUBLE,\
        SEPALWIDTHCM  DOUBLE,\
        PETALLENGTHCM DOUBLE,\
        PETALWIDTHCM  DOUBLE,\
        SPECIES       NVARCHAR(15)\
    )'
        inlist = '("SEPALLENGTHCM", "SEPALWIDTHCM", "PETALLENGTHCM", "PETALWIDTHCM", "SPECIES")\
                    VALUES (?, ?, ?, ?, ?)'
        DataSets._load_data(connection, table_descriptions, cols, inlist)
        return full_tbl, training_tbl, validation_tbl, test_tbl

    @staticmethod
    def load_boston_housing_data(connection, schema=None):
        if schema is None:
            schema = Settings.user
        full_tbl = "BOSTON_HOUSING_PRICES"
        training_tbl = "BOSTON_HOUSING_PRICES_TRAINING"
        validation_tbl = "BOSTON_HOUSING_PRICES_VALIDATION"
        test_tbl = "BOSTON_HOUSING_PRICES_TEST"
        full_tbl_fq = schema + '.' + full_tbl
        training_tbl_fq = schema + '.' + training_tbl
        validation_tbl_fq = schema + '.' + validation_tbl
        test_tbl_fq = schema + '.' + test_tbl
        table_descriptions = {
                      'full':       [full_tbl_fq, '../datasets/boston-house-prices.csv'],
                      'train':      [training_tbl_fq, '../datasets/boston-house-prices-train.csv'],
                      'validation': [validation_tbl_fq, '../datasets/boston-house-prices-validation.csv'],
                      'test':       [test_tbl_fq, '../datasets/boston-house-prices-test.csv']
                      }

        cols = '( \
        "CRIM" DECIMAL(12,5) CS_FIXED,\
        "ZN" DECIMAL(7,3) CS_FIXED,\
        "INDUS" DECIMAL(7,2) CS_FIXED,\
        "CHAS" SMALLINT CS_INT, "NOX" DECIMAL(10,4) CS_FIXED,\
        "RM" DECIMAL(8,3) CS_FIXED,\
        "AGE" DECIMAL(7,3) CS_FIXED,\
        "DIS" DECIMAL(11,4) CS_FIXED,\
        "RAD" TINYINT CS_INT,\
        "TAX" SMALLINT CS_INT,\
        "PTRATIO" DECIMAL(6,2) CS_FIXED,\
        "BLACK" DECIMAL(9,3) CS_FIXED,\
        "LSTAT" DECIMAL(7,2) CS_FIXED,\
        "MEDV" DECIMAL(6,2) CS_FIXED,\
        "ID" INTEGER\
        )'
        inlist = '("CRIM", "ZN", "INDUS", "CHAS",\
                    "NOX", "RM", "AGE", "DIS", "RAD", "TAX", "PTRATIO", "BLACK", "LSTAT", "MEDV", "ID") \
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'
        DataSets._load_data(connection, table_descriptions, cols, inlist)
        return full_tbl, training_tbl, validation_tbl, test_tbl

